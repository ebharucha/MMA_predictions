{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMA_predictions\n",
    "Using basic supervised learning to predict fight outcomes\n",
    "\n",
    "The current dataset is restricted to the UFC\n",
    "\n",
    "Have not fine tuned any of the models.\n",
    "The Deep Learning models are WIP & not operational\n",
    "\n",
    "The overall proecss of acquiring data and running the models needs to be automated.  \n",
    "\n",
    "<b>To run:</b>\n",
    "\n",
    "## Step 1\n",
    "Create \"fight_card.xlsx\" in the data directory with the following structure\n",
    "weight_class      fighter1    fighter2\n",
    "or populate the 'df_fight_card' DataFrame\n",
    "This contains the bouts for which outcomes would get predicted\n",
    "\n",
    "## Step 2\n",
    "Execute the 'Load Dependencies' section\n",
    "\n",
    "## Step 3\n",
    "Execute the 'Load Datasets' section\n",
    "\n",
    "## Step 4\n",
    "Execute the 'Predict' section\n",
    "\n",
    "<i>Ed Bharucha</i> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import requests\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# warnings.filterwarnings(action='once')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(scaler, data):\n",
    "  if (scaler == 'standard'):\n",
    "    std_scaler = StandardScaler()\n",
    "    return (std_scaler.fit_transform(data))\n",
    "  elif (scaler == 'minmax'):\n",
    "    minmax_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    return (minmax_scaler.fit_transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire & Prepare Fight Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fighter stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = []\n",
    "last_names = []\n",
    "nick_names = []\n",
    "heights = []\n",
    "weights = []\n",
    "reaches = []\n",
    "stances = []\n",
    "wins = []\n",
    "losses = []\n",
    "draws = []\n",
    "fighter_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(string.ascii_lowercase):\n",
    "    fighters_url = f'http://ufcstats.com/statistics/fighters?char={c}&page=all'\n",
    "    \n",
    "    page = requests.get(fighters_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    fighters_data = soup.find_all('tr')\n",
    "\n",
    "    for fighter in fighters_data[2:]:\n",
    "        fighter_data = fighter.find_all('td')\n",
    "        first_names.append(fighter_data[0].get_text(strip=True))\n",
    "        last_names.append(fighter_data[1].get_text(strip=True))\n",
    "        nick_names.append(fighter_data[2].get_text(strip=True))\n",
    "        heights.append(fighter_data[3].get_text(strip=True))\n",
    "        weights.append(fighter_data[4].get_text(strip=True))\n",
    "        reaches.append(fighter_data[5].get_text(strip=True))\n",
    "        stances.append(fighter_data[6].get_text(strip=True))\n",
    "        wins.append(fighter_data[7].get_text(strip=True))\n",
    "        losses.append(fighter_data[8].get_text(strip=True))\n",
    "        draws.append(fighter_data[9].get_text(strip=True))\n",
    "        fighter_urls.append(fighter_data[0].find('a')['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_data = pd.DataFrame(\n",
    "    {\n",
    "        'first_name' : first_names,\n",
    "        'last_name' : last_names,\n",
    "        'nick_name' : nick_names,\n",
    "        'height' : heights,\n",
    "        'weight' : weights,\n",
    "        'reach' : reaches,\n",
    "        'stance' : stances,\n",
    "        'wins' : wins,\n",
    "        'losses' : losses,\n",
    "        'draws' : draws,\n",
    "        'fighter_url' : fighter_urls,\n",
    "    }\n",
    ")\n",
    "\n",
    "fighter_data.to_csv('data/fighter_data_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_cm(height):\n",
    "    try:\n",
    "        feet = height.split('\"')[0].split(\"'\")[0]\n",
    "    except:\n",
    "        feet = ''\n",
    "    try:\n",
    "        inches = height.split('\"')[0].split(\"'\")[1]\n",
    "    except:\n",
    "        inches = ''\n",
    "\n",
    "    if not feet.strip().isdigit():\n",
    "        feet = 0\n",
    "    if not inches.strip().isdigit():\n",
    "        inches = 0\n",
    "    return (int(feet)*30.48 + int(inches)*2.54)\n",
    "\n",
    "def reach_cm(reach):\n",
    "    regnumber = re.compile(r'\\d+(?:,\\d*)?')\n",
    "    rch = reach.split('\"')[0]\n",
    "\n",
    "    if regnumber.match(rch.strip()):\n",
    "        inches = rch.split('.')[0]\n",
    "    else:\n",
    "        inches = 0\n",
    "    \n",
    "    return(int(inches)*2.54)\n",
    "\n",
    "def weight_lbs(weight):\n",
    "    lbs = weight.split(' ')[0]\n",
    "    if not lbs.strip().isdigit():\n",
    "        lbs = 0\n",
    "    \n",
    "    return(int(lbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_data['height'] = fighter_data['height'].apply(lambda x: height_cm(x))\n",
    "fighter_data['reach'] = fighter_data['reach'].apply(lambda x: reach_cm(x))\n",
    "fighter_data['weight'] = fighter_data['weight'].apply(lambda x: weight_lbs(x))\n",
    "\n",
    "fighter_data.wins = pd.to_numeric(fighter_data.wins)\n",
    "fighter_data.losses = pd.to_numeric(fighter_data.losses)\n",
    "fighter_data.draws = pd.to_numeric(fighter_data.draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLpM = []\n",
    "Str_Acc = []\n",
    "SApM = []\n",
    "Str_Dep = []\n",
    "TD_Avg = []\n",
    "TD_Acc = []\n",
    "TD_Def = []\n",
    "Sub_Avg = []\n",
    "\n",
    "for url in tqdm(fighter_data.fighter_url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    career_stats = soup.find(class_='b-list__info-box b-list__info-box_style_middle-width js-guide clearfix').find_all('li')\n",
    "    \n",
    "    SLpM.append(career_stats[0].get_text(strip=True).split(':')[1])\n",
    "    Str_Acc.append(career_stats[1].get_text(strip=True).split(':')[1])\n",
    "    SApM.append(career_stats[2].get_text(strip=True).split(':')[1])\n",
    "    Str_Dep.append(career_stats[3].get_text(strip=True).split(':')[1])\n",
    "    TD_Avg.append(career_stats[5].get_text(strip=True).split(':')[1])\n",
    "    TD_Acc.append(career_stats[6].get_text(strip=True).split(':')[1])\n",
    "    TD_Def.append(career_stats[7].get_text(strip=True).split(':')[1])\n",
    "    Sub_Avg.append(career_stats[8].get_text(strip=True).split(':')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_data['full_name'] = fighter_data.first_name + \" \" + fighter_data.last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fighter_data.to_csv('../data/fighter_data.csv')\n",
    "# with open ('../data/fighter_data.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fighter_data, pklfile)\n",
    "\n",
    "with open ('../data/fighter_data.pkl', 'rb') as pklfile:\n",
    "    fighter_data = pickle.load(pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fight results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fight_data_url = 'http://ufcstats.com/statistics/events/completed?page=all'\n",
    "\n",
    "page = requests.get(fight_data_url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fight_list = soup.find('tbody').find_all('a')\n",
    "fight_card_names = [fight.get_text(strip=True) for fight in fight_list]\n",
    "fight_card_urls = [fight['href'] for fight in fight_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fight_card = []\n",
    "fight_card_url = []\n",
    "fighter1 = []\n",
    "fighter2 = []\n",
    "weight_class = []\n",
    "winner = []\n",
    "method = []\n",
    "round_ = []\n",
    "i = 0\n",
    "\n",
    "for url in tqdm(fight_card_urls[1:]):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content,'html.parser')\n",
    "    full_fight_card = soup.find('tbody')\n",
    "    full_fight_card_fights = full_fight_card.find_all('tr')\n",
    "    for fight in full_fight_card_fights:\n",
    "        fight_card.append(fight_card_names[i+1])\n",
    "        fight_card_url.append(url)\n",
    "        fighter1.append(fight.find_all('td')[1].find_all('a')[0].get_text(strip=True))\n",
    "        fighter2.append(fight.find_all('td')[1].find_all('a')[1].get_text(strip=True))\n",
    "        weight_class.append(fight.find_all('td')[6].get_text(strip=True))\n",
    "        winner.append(fighter1[-1])\n",
    "        method.append(fight.find_all('td')[7].get_text(strip=True))\n",
    "        round_.append(fight.find_all('td')[8].get_text(strip=True))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fight_card_data = pd.DataFrame(\n",
    "    {\n",
    "        'fight_card' : fight_card,\n",
    "        'fight_card_url' : fight_card_url,\n",
    "        'fighter1' : fighter1,\n",
    "        'fighter2' : fighter2,\n",
    "        'weight_class' : weight_class,\n",
    "        'winner' : winner,\n",
    "        'method' : method,\n",
    "        'round' : round_,\n",
    "    }\n",
    ")\n",
    "\n",
    "fight_card_data.to_csv('../data/fight_card_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_idx = 25\n",
    "inc = 25\n",
    "end_idx = start_idx + inc\n",
    "\n",
    "fight_card_data_ = fight_card_data\n",
    "\n",
    "while start_idx <= fight_card_data.shape[0]:\n",
    "    fight_card_data_.loc[start_idx:end_idx,['fighter1', 'fighter2']] = fight_card_data_.loc[start_idx:end_idx,['fighter2', 'fighter1']].values\n",
    "    start_idx = end_idx + 25\n",
    "    end_idx = start_idx + inc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with open ('../data/fight_card_data.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fight_card_data, pklfile)\n",
    "\n",
    "# with open ('../data/fight_card_data_.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fight_card_data_, pklfile)\n",
    "\n",
    "# with open ('../data/fight_card_data.pkl', 'rb') as pklfile:\n",
    "#     fight_card_data = pickle.load(pklfile)\n",
    "    \n",
    "with open ('../data/fight_card_data_.pkl', 'rb') as pklfile:\n",
    "    fight_card_data_ = pickle.load(pklfile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated dataset (fights + fighter stats.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_card_data_ = fight_card_data_.merge(fighter_data, left_on=['fighter1'], right_on=['full_name'], how='left').\\\n",
    "drop(columns=['first_name', 'last_name', 'nick_name', 'fighter_url'])\n",
    "\n",
    "fight_card_data_.rename(columns={'height':'fighter1_height', 'weight':'fighter1_weight', 'reach':'fighter1_reach',\\\n",
    "                                 'stance':'fighter1_stance','wins':'fighter1_wins', 'losses':'fighter1_losses',\\\n",
    "                                 'draws':'fighter1_draws', 'SLpM':'fighter1_SLpM', 'Str_Acc':'fighter1_Str_Acc',\\\n",
    "                                 'SApM':'fighter1_SApM', 'Str_Dep':'fighter1_Str_Dep','TD_Avg':'fighter1_TD_Avg',\\\n",
    "                                 'TD_Acc':'fighter1_TD_Acc', 'TD_Def':'fighter1_TD_Def',\\\n",
    "                                 'Sub_Avg':'fighter1_Sub_Avg','full_name':'fighter1_full_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_card_data_ = fight_card_data_.merge(fighter_data, left_on=['fighter2'], right_on=['full_name'], how='left').\\\n",
    "drop(columns=['first_name', 'last_name', 'nick_name', 'fighter_url'])\n",
    "\n",
    "fight_card_data_.rename(columns={'height':'fighter2_height', 'weight':'fighter2_weight', 'reach':'fighter2_reach',\\\n",
    "                                 'stance':'fighter2_stance','wins':'fighter2_wins', 'losses':'fighter2_losses',\\\n",
    "                                 'draws':'fighter2_draws', 'SLpM':'fighter2_SLpM', 'Str_Acc':'fighter2_Str_Acc',\\\n",
    "                                 'SApM':'fighter2_SApM', 'Str_Dep':'fighter2_Str_Dep','TD_Avg':'fighter2_TD_Avg',\\\n",
    "                                 'TD_Acc':'fighter2_TD_Acc', 'TD_Def':'fighter2_TD_Def',\\\n",
    "                                 'Sub_Avg':'fighter2_Sub_Avg','full_name':'fighter2_full_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('../data/fight_data_full.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fight_card_data_, pklfile)\n",
    "    \n",
    "with open ('../data/fight_data_full.pkl', 'rb') as pklfile:\n",
    "    fight_data_full = pickle.load(pklfile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalize & Encode dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('../data/fighter_data.pkl', 'rb') as pklfile:\n",
    "    fighter_data = pickle.load(pklfile)\n",
    "\n",
    "with open ('../data/fighter_data_en.pkl', 'rb') as pklfile:\n",
    "    fighter_data_en = pickle.load(pklfile)    \n",
    "    \n",
    "with open ('../data/fight_card_data_.pkl', 'rb') as pklfile:\n",
    "    fight_card_data_ = pickle.load(pklfile)   \n",
    "    \n",
    "with open ('../data/fight_data_full.pkl', 'rb') as pklfile:\n",
    "    fight_data_full = pickle.load(pklfile) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Fighter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ([f'{col}=>{type(fighter_data[col][0])} ' for col in fighter_data.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode fighter data\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.HashingEncoder(cols = ['stance'])\n",
    "fighter_data = enc.fit_transform(fighter_data)\n",
    "\n",
    "fighter_data['SLpM'] = pd.to_numeric(fighter_data['SLpM'])\n",
    "\n",
    "fighter_data['Str_Acc'] = fighter_data['Str_Acc'].str.replace('%', '')\n",
    "fighter_data['Str_Acc'] = pd.to_numeric(fighter_data['Str_Acc'])\n",
    "\n",
    "fighter_data['SApM'] = pd.to_numeric(fighter_data['SApM'])\n",
    "\n",
    "fighter_data['Str_Dep'] = fighter_data['Str_Dep'].str.replace('%', '')\n",
    "fighter_data['Str_Dep'] = pd.to_numeric(fighter_data['Str_Dep'])\n",
    "\n",
    "fighter_data['TD_Avg'] = pd.to_numeric(fighter_data['TD_Avg'])\n",
    "\n",
    "fighter_data['TD_Acc'] = fighter_data['TD_Acc'].str.replace('%', '')\n",
    "fighter_data['TD_Acc'] = pd.to_numeric(fighter_data['TD_Acc'])\n",
    "\n",
    "fighter_data['TD_Def'] = fighter_data['TD_Def'].str.replace('%', '')\n",
    "fighter_data['TD_Def'] = pd.to_numeric(fighter_data['TD_Def'])\n",
    "\n",
    "fighter_data['Sub_Avg'] = pd.to_numeric(fighter_data['Sub_Avg'])\n",
    "\n",
    "# with open ('../data/fighter_data_en.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fighter_data, pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_full_name_unique = fighter_data.full_name.unique()\n",
    "\n",
    "enc = ce.OrdinalEncoder(fighter_full_name_unique)\n",
    "fighter_full_name_unique_enc = enc.fit_transform(fighter_full_name_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fighter1', 'fighter2', 'weight_class','winner', \\\n",
    "        'fighter1_height', 'fighter1_weight','fighter1_reach', 'fighter1_stance',\\\n",
    "        'fighter1_wins', 'fighter1_losses', 'fighter1_draws', 'fighter1_SLpM',\\\n",
    "        'fighter1_Str_Acc', 'fighter1_SApM', 'fighter1_Str_Dep', 'fighter1_TD_Avg',\\\n",
    "        'fighter1_TD_Acc', 'fighter1_TD_Def', 'fighter1_Sub_Avg',\\\n",
    "        'fighter2_height', 'fighter2_weight', 'fighter2_reach', 'fighter2_stance',\\\n",
    "        'fighter2_wins', 'fighter2_losses', 'fighter2_draws', 'fighter2_SLpM',\\\n",
    "        'fighter2_Str_Acc', 'fighter2_SApM', 'fighter2_Str_Dep', 'fighter2_TD_Avg',\\\n",
    "        'fighter2_TD_Acc', 'fighter2_TD_Def', 'fighter2_Sub_Avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_data_full_ = fight_data_full[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.HashingEncoder(cols = ['weight_class', 'fighter1_stance', 'fighter2_stance'])\n",
    "fight_data_full_ = enc.fit_transform(fight_data_full_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Relevant Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Fighter Data\n",
    "\n",
    "fighter_relevant_cols = ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7',\n",
    "       'height', 'weight', 'reach',\n",
    "       'wins', 'losses', 'draws', 'SLpM', 'Str_Acc', 'SApM',\n",
    "       'Str_Dep', 'TD_Avg', 'TD_Acc', 'TD_Def', 'Sub_Avg', 'full_name']\n",
    "fighter_data_relevant = fighter_data_en[fighter_relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighter_data_relevant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant Fight Data\n",
    "\n",
    "fight_data_relevant = fight_data_full[['fighter1', 'fighter2', 'weight_class', 'winner']]\n",
    "fight_data_relevant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for fighter 1\n",
    "\n",
    "fight_data_relevant = fight_data_relevant.merge(fighter_data_relevant, left_on=['fighter1'], right_on=['full_name'],\\\n",
    "                                                how='left').drop(columns=['full_name'])\n",
    "fight_data_relevant.rename(columns={'col_0':'col_0_fighter1', 'col_1':'col_1_fighter1', 'col_2':'col_2_fighter1',\\\n",
    "                                    'col_3':'col_3_fighter1', 'col_4':'col_4_fighter1', 'col_5':'col_5_fighter1',\\\n",
    "                                    'col_6':'col_6_fighter1', 'col_7':'col_7_fighter1',\\\n",
    "                                    'height':'height_fighter1', 'weight':'weight_fighter1', 'reach':'reach_fighter1',\\\n",
    "                                    'wins':'wins_fighter1', 'losses':'losses_fighter1', 'draws':'draws_fighter1',\\\n",
    "                                    'SLpM':'SLpM_fighter1','Str_Acc':'Str_Acc_fighter1', 'SApM':'SApM_fighter1',\\\n",
    "                                    'Str_Dep':'Str_Dep_fighter1', 'TD_Avg':'TD_Avg_fighter1', 'TD_Acc':'TD_Acc_fighter1',\\\n",
    "                                    'TD_Def':'TD_Def_fighter1', 'Sub_Avg':'Sub_Avg_fighter1'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for fighter 2\n",
    "\n",
    "fight_data_relevant = fight_data_relevant.merge(fighter_data_relevant, left_on=['fighter2'], right_on=['full_name'],\\\n",
    "                                                how='left').drop(columns=['full_name'])\n",
    "fight_data_relevant.rename(columns={'col_0':'col_0_fighter2', 'col_1':'col_1_fighter2', 'col_2':'col_2_fighter2',\\\n",
    "                                    'col_3':'col_3_fighter2', 'col_4':'col_4_fighter2', 'col_5':'col_5_fighter2',\\\n",
    "                                    'col_6':'col_6_fighter2', 'col_7':'col_7_fighter2',\\\n",
    "                                    'height':'height_fighter2', 'weight':'weight_fighter2', 'reach':'reach_fighter2',\\\n",
    "                                    'wins':'wins_fighter2', 'losses':'losses_fighter2', 'draws':'draws_fighter2',\\\n",
    "                                    'SLpM':'SLpM_fighter2','Str_Acc':'Str_Acc_fighter2', 'SApM':'SApM_fighter2',\\\n",
    "                                    'Str_Dep':'Str_Dep_fighter2', 'TD_Avg':'TD_Avg_fighter2', 'TD_Acc':'TD_Acc_fighter2',\\\n",
    "                                    'TD_Def':'TD_Def_fighter2', 'Sub_Avg':'Sub_Avg_fighter2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode weight class\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "enc = ce.HashingEncoder(cols = ['weight_class'])\n",
    "fight_data_relevant = enc.fit_transform(fight_data_relevant)\n",
    "fight_data_relevant.rename(columns={'col_0':'col_0_weight_class', 'col_1':'col_1_weight_class', 'col_2':'col_2_weight_class',\\\n",
    "                                    'col_3':'col_3_weight_class', 'col_4':'col_4_weight_class', 'col_5':'col_5_weight_class',\\\n",
    "                                    'col_6':'col_6_weight_class', 'col_7':'col_7_weight_class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode winner\n",
    "\n",
    "fight_data_relevant_en = fight_data_relevant.copy()\n",
    "fight_data_relevant['winner_en'] = np.where(fight_data_relevant['winner']==fight_data_relevant['fighter1'], 0, 1)\n",
    "fight_data_relevant.drop(columns=['fighter1', 'fighter2', 'winner'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('../data/fight_data_relevant.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fight_data_relevant, pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Misc Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fighter_full_name = pd.DataFrame()\n",
    "fighter_full_name['full_name'] = fighter_full_name_unique\n",
    "fighter_full_name['full_name_enc'] = fighter_full_name_unique_enc\n",
    "fighter_full_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fight_data_full_ = fight_data_full_.merge(fighter_full_name, left_on=['fighter1'], right_on=['full_name'],\\\n",
    "#                                           how='left').drop(columns=['full_name', 'fighter1'])\n",
    "# fight_data_full_.rename(columns={'full_name_enc':'fighter1_enc'}, inplace=True)\n",
    "\n",
    "# fight_data_full_ = fight_data_full_.merge(fighter_full_name, left_on=['fighter2'], right_on=['full_name'],\\\n",
    "#                                           how='left').drop(columns=['full_name', 'fighter2'])\n",
    "# fight_data_full_.rename(columns={'full_name_enc':'fighter2_enc'}, inplace=True)\n",
    "\n",
    "# fight_data_full_ = fight_data_full_.merge(fighter_full_name, left_on=['winner'], right_on=['full_name'],\\\n",
    "#                                           how='left').drop(columns=['full_name', 'winner'])\n",
    "# fight_data_full_.rename(columns={'full_name_enc':'winner_enc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fight_data_full_.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fight_data_full_['round'] = pd.to_numeric(fight_data_full_['round'])\n",
    "\n",
    "# fight_data_full_['fighter1_SLpM'] = pd.to_numeric(fight_data_full_['fighter1_SLpM'])\n",
    "\n",
    "# fight_data_full_['fighter1_Str_Acc'] = fight_data_full_['fighter1_Str_Acc'].str.replace('%', '')\n",
    "# fight_data_full_['fighter1_Str_Acc'] = pd.to_numeric(fight_data_full_['fighter1_Str_Acc'])\n",
    "\n",
    "# fight_data_full_['fighter1_SApM'] = pd.to_numeric(fight_data_full_['fighter1_SApM'])\n",
    "\n",
    "# fight_data_full_['fighter1_Str_Dep'] = fight_data_full_['fighter1_Str_Dep'].str.replace('%', '')\n",
    "# fight_data_full_['fighter1_Str_Dep'] = pd.to_numeric(fight_data_full_['fighter1_Str_Dep'])\n",
    "\n",
    "# fight_data_full_['fighter1_TD_Avg'] = pd.to_numeric(fight_data_full_['fighter1_TD_Avg'])\n",
    "\n",
    "# fight_data_full_['fighter1_TD_Acc'] = fight_data_full_['fighter1_TD_Acc'].str.replace('%', '')\n",
    "# fight_data_full_['fighter1_TD_Acc'] = pd.to_numeric(fight_data_full_['fighter1_TD_Acc'])\n",
    "\n",
    "# fight_data_full_['fighter1_TD_Def'] = fight_data_full_['fighter1_TD_Def'].str.replace('%', '')\n",
    "# fight_data_full_['fighter1_TD_Def'] = pd.to_numeric(fight_data_full_['fighter1_TD_Def'])\n",
    "\n",
    "# fight_data_full_['fighter1_Sub_Avg'] = pd.to_numeric(fight_data_full_['fighter1_Sub_Avg'])\n",
    "\n",
    "# fight_data_full_['fighter2_SLpM'] = pd.to_numeric(fight_data_full_['fighter2_SLpM'])\n",
    "# fight_data_full_['fighter2_SApM'] = pd.to_numeric(fight_data_full_['fighter2_SApM'])\n",
    "# fight_data_full_['fighter2_TD_Avg'] = pd.to_numeric(fight_data_full_['fighter2_TD_Avg'])\n",
    "# fight_data_full_['fighter2_Sub_Avg'] = pd.to_numeric(fight_data_full_['fighter2_Sub_Avg'])\n",
    "\n",
    "# fight_data_full_['fighter2_Str_Acc'] = fight_data_full_['fighter2_Str_Acc'].str.replace('%', '')\n",
    "# fight_data_full_['fighter2_Str_Acc'] = pd.to_numeric(fight_data_full_['fighter2_Str_Acc'])\n",
    "\n",
    "# fight_data_full_['fighter2_Str_Dep'] = fight_data_full_['fighter2_Str_Dep'].str.replace('%', '')\n",
    "# fight_data_full_['fighter2_Str_Dep'] = pd.to_numeric(fight_data_full_['fighter2_Str_Dep'])\n",
    "\n",
    "# fight_data_full_['fighter2_TD_Acc'] = fight_data_full_['fighter2_TD_Acc'].str.replace('%', '')\n",
    "# fight_data_full_['fighter2_TD_Acc'] = pd.to_numeric(fight_data_full_['fighter2_TD_Acc'])\n",
    "\n",
    "# fight_data_full_['fighter2_TD_Def'] = fight_data_full_['fighter2_TD_Def'].str.replace('%', '')\n",
    "# fight_data_full_['fighter2_TD_Def'] = pd.to_numeric(fight_data_full_['fighter2_TD_Def'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for col in fight_data_full_.columns.tolist():\n",
    "    print (f'{col} => {type(fight_data_full_.loc[0][col])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# with open('../data/fighter_full_name.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fighter_full_name, pklfile)\n",
    "\n",
    "# with open('../data/fight_data_full_en.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(fight_data_full_, pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open ('../data/fighter_data.pkl', 'rb') as pklfile:\n",
    "#     fighter_data = pickle.load(pklfile)\n",
    "\n",
    "# with open ('../data/fighter_data_en.pkl', 'rb') as pklfile:\n",
    "#     fighter_data_en = pickle.load(pklfile)\n",
    "\n",
    "# with open ('../data/fighter_data_relevant.pkl', 'rb') as pklfile:\n",
    "#     fighter_data_relevant = pickle.load(pklfile)    \n",
    "    \n",
    "# with open ('../data/fighter_full_name.pkl', 'rb') as pklfile:\n",
    "#     fighter_full_name = pickle.load(pklfile)    \n",
    "\n",
    "# with open ('../data/fight_card_data_.pkl', 'rb') as pklfile:\n",
    "#     fight_card_data_ = pickle.load(pklfile)   \n",
    "    \n",
    "# with open ('../data/fight_data_full.pkl', 'rb') as pklfile:\n",
    "#     fight_data_full = pickle.load(pklfile) \n",
    "    \n",
    "# with open ('../data/fight_data_full_en.pkl', 'rb') as pklfile:\n",
    "#     fight_data_full_en = pickle.load(pklfile)\n",
    "\n",
    "# with open ('../data/fight_data_relevant.pkl', 'rb') as pklfile:\n",
    "#     fight_data_relevant = pickle.load(pklfile)\n",
    "    \n",
    "    \n",
    "with open ('../data/fight_data_final.pkl', 'rb') as pklfile:\n",
    "    fight_data_final = pickle.load(pklfile)\n",
    "    \n",
    "with open ('../data/fight_card_final.pkl', 'rb') as pklfile:\n",
    "    fight_card_final = pickle.load(pklfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open ('../data/backup/fight_data_relevant.pkl', 'rb') as pklfile:\n",
    "    fight_data_relevant = pickle.load(pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_0_weight_class', 'col_1_weight_class', 'col_2_weight_class',\n",
       "       'col_3_weight_class', 'col_4_weight_class', 'col_5_weight_class',\n",
       "       'col_6_weight_class', 'col_7_weight_class', 'col_0_fighter1',\n",
       "       'col_1_fighter1', 'col_2_fighter1', 'col_3_fighter1', 'col_4_fighter1',\n",
       "       'col_5_fighter1', 'col_6_fighter1', 'col_7_fighter1', 'height_fighter1',\n",
       "       'weight_fighter1', 'reach_fighter1', 'wins_fighter1', 'losses_fighter1',\n",
       "       'draws_fighter1', 'SLpM_fighter1', 'Str_Acc_fighter1', 'SApM_fighter1',\n",
       "       'Str_Dep_fighter1', 'TD_Avg_fighter1', 'TD_Acc_fighter1',\n",
       "       'TD_Def_fighter1', 'Sub_Avg_fighter1', 'col_0_fighter2',\n",
       "       'col_1_fighter2', 'col_2_fighter2', 'col_3_fighter2', 'col_4_fighter2',\n",
       "       'col_5_fighter2', 'col_6_fighter2', 'col_7_fighter2', 'height_fighter2',\n",
       "       'weight_fighter2', 'reach_fighter2', 'wins_fighter2', 'losses_fighter2',\n",
       "       'draws_fighter2', 'SLpM_fighter2', 'Str_Acc_fighter2', 'SApM_fighter2',\n",
       "       'Str_Dep_fighter2', 'TD_Avg_fighter2', 'TD_Acc_fighter2',\n",
       "       'TD_Def_fighter2', 'Sub_Avg_fighter2', 'winner_en'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fight_data_relevant.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# X = scale('standard', fight_data_full_en.iloc[:,:-1])\n",
    "# y = fight_data_full_en.iloc[:,-1]\n",
    "\n",
    "X = scale('standard', fight_data_relevant.iloc[:,:-1])\n",
    "y = fight_data_relevant.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pca (data):\n",
    "  from sklearn.decomposition import PCA\n",
    "#   pca = PCA(n_components=10)\n",
    "  pca = PCA(.95)   # retain 95% of variance\n",
    "  principalComponents_train = pca.fit_transform(data)\n",
    "  pac_vars_train = [print (f'{pac_var*100:.2f}%\\t', end=\"\") for pac_var in pca.explained_variance_ratio_]\n",
    "  print ()\n",
    "  print (f'{np.sum(pca.explained_variance_ratio_)*100:.2f}%')\n",
    "  return (principalComponents_train)\n",
    "\n",
    "X_scaled = scale('standard', fight_data_relevant.iloc[:,:-1])\n",
    "pc = pca(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### cross_val_score on ML Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Random Forrest\n",
    "\n",
    "# score_rf = cross_val_score(RandomForestClassifier(n_estimators=100), X, y, cv=3)\n",
    "score_rf = cross_val_score(RandomForestClassifier(n_estimators=100), pc, y, cv=3)\n",
    "np.mean(score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "\n",
    "lgb_params = {\n",
    "                 'boosting_type' : 'dart', 'objective' : 'binary','learning_rate' : 0.06,\n",
    "                  'n_estimators' : 500,  'max_bin' : 100, 'n_jobs' : 2, 'num_leaves' : 50,\n",
    "                 }\n",
    "\n",
    "\n",
    "lgb_params = {\n",
    "                 'n_estimators' : 500, 'boosting_type' : 'dart'\n",
    "                 }\n",
    "\n",
    "score_lgb = cross_val_score(lgb.LGBMClassifier(**lgb_params),X, y, cv=5,)\n",
    "# score_lgb = cross_val_score(\n",
    "#     lgb.LGBMClassifier(objective='binary', metric='binary_logloss', n_estimators=100, num_leaves=10,), \n",
    "#     pc, y, cv=5,)\n",
    "np.mean(score_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shallow Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Series([], Name: full_name, dtype: object),\n",
       " array(['Heavyweight', 'Welterweight', 'Middleweight', 'Featherweight',\n",
       "        'Lightweight', 'Bantamweight', 'Catch Weight',\n",
       "        \"Women's Strawweight\", \"Women's Flyweight\", 'Light Heavyweight',\n",
       "        'Flyweight', \"Women's Featherweight\", \"Women's Bantamweight\",\n",
       "        'Super Heavyweight', 'Open Weight'], dtype=object))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('../data/backup/fighter_data.pkl', 'rb') as pklfile:\n",
    "    fighter_data = pickle.load(pklfile)\n",
    "\n",
    "with open ('../data/backup/fight_data_full.pkl', 'rb') as pklfile:\n",
    "    fight_data_full = pickle.load(pklfile)     \n",
    "    \n",
    "fighter_data[fighter_data['full_name'].str.contains('Ziam')].full_name, fight_data_full.weight_class.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class_col_0</th>\n",
       "      <th>weight_class_col_1</th>\n",
       "      <th>weight_class_col_2</th>\n",
       "      <th>weight_class_col_3</th>\n",
       "      <th>weight_class_col_4</th>\n",
       "      <th>weight_class_col_5</th>\n",
       "      <th>weight_class_col_6</th>\n",
       "      <th>weight_class_col_7</th>\n",
       "      <th>fighter1</th>\n",
       "      <th>fighter2</th>\n",
       "      <th>...</th>\n",
       "      <th>draws_fighter2</th>\n",
       "      <th>SLpM_fighter2</th>\n",
       "      <th>Str_Acc_fighter2</th>\n",
       "      <th>SApM_fighter2</th>\n",
       "      <th>Str_Dep_fighter2</th>\n",
       "      <th>TD_Avg_fighter2</th>\n",
       "      <th>TD_Acc_fighter2</th>\n",
       "      <th>TD_Def_fighter2</th>\n",
       "      <th>Sub_Avg_fighter2</th>\n",
       "      <th>winner_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Weili Zhang</td>\n",
       "      <td>Jessica Andrade</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>51</td>\n",
       "      <td>5.28</td>\n",
       "      <td>51</td>\n",
       "      <td>3.21</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jingliang Li</td>\n",
       "      <td>Elizeu Zaleski dos Santos</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.18</td>\n",
       "      <td>39</td>\n",
       "      <td>3.03</td>\n",
       "      <td>61</td>\n",
       "      <td>0.45</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Kai Kara-France</td>\n",
       "      <td>Mark De La Rosa</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>36</td>\n",
       "      <td>4.04</td>\n",
       "      <td>53</td>\n",
       "      <td>0.77</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Kenan Song</td>\n",
       "      <td>Derrick Krantz</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>37</td>\n",
       "      <td>4.03</td>\n",
       "      <td>50</td>\n",
       "      <td>3.18</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mizuki Inoue</td>\n",
       "      <td>Yanan Wu</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4.79</td>\n",
       "      <td>45</td>\n",
       "      <td>4.35</td>\n",
       "      <td>52</td>\n",
       "      <td>0.44</td>\n",
       "      <td>14</td>\n",
       "      <td>58</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_class_col_0  weight_class_col_1  weight_class_col_2  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   1   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   1   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   weight_class_col_3  weight_class_col_4  weight_class_col_5  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   1                   0                   0   \n",
       "\n",
       "   weight_class_col_6  weight_class_col_7         fighter1  \\\n",
       "0                   1                   0      Weili Zhang   \n",
       "1                   0                   0     Jingliang Li   \n",
       "2                   1                   0  Kai Kara-France   \n",
       "3                   0                   0       Kenan Song   \n",
       "4                   0                   0     Mizuki Inoue   \n",
       "\n",
       "                    fighter2  ... draws_fighter2  SLpM_fighter2  \\\n",
       "0            Jessica Andrade  ...              0           6.55   \n",
       "1  Elizeu Zaleski dos Santos  ...              0           4.18   \n",
       "2            Mark De La Rosa  ...              0           3.05   \n",
       "3             Derrick Krantz  ...              0           2.07   \n",
       "4                   Yanan Wu  ...              0           4.79   \n",
       "\n",
       "   Str_Acc_fighter2  SApM_fighter2  Str_Dep_fighter2  TD_Avg_fighter2  \\\n",
       "0                51           5.28                51             3.21   \n",
       "1                39           3.03                61             0.45   \n",
       "2                36           4.04                53             0.77   \n",
       "3                37           4.03                50             3.18   \n",
       "4                45           4.35                52             0.44   \n",
       "\n",
       "   TD_Acc_fighter2  TD_Def_fighter2  Sub_Avg_fighter2  winner_en  \n",
       "0               58               76               0.5          0  \n",
       "1               14               48               0.6          0  \n",
       "2               17               42               0.3          0  \n",
       "3               50                0               0.8          0  \n",
       "4               14               58               0.4          0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fight_data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(df_fight_card, fighter_data_relevant):\n",
    "    enc = ce.HashingEncoder(cols = ['weight_class'])\n",
    "    X_test = enc.fit_transform(df_fight_card)\n",
    "    X_test.rename(columns={'col_0':'col_0_weight_class', 'col_1':'col_1_weight_class', 'col_2':'col_2_weight_class',\\\n",
    "                                    'col_3':'col_3_weight_class', 'col_4':'col_4_weight_class', 'col_5':'col_5_weight_class',\\\n",
    "                                    'col_6':'col_6_weight_class', 'col_7':'col_7_weight_class'}, inplace=True)\n",
    "\n",
    "    # Get data for fighter1\n",
    "\n",
    "    X_test = X_test.merge(fighter_data_relevant, left_on=['fighter1'], right_on=['full_name'],\\\n",
    "                                                    how='left').drop(columns=['full_name', 'fighter1'])\n",
    "    X_test.rename(columns={'col_0':'col_0_fighter1', 'col_1':'col_1_fighter1', 'col_2':'col_2_fighter1',\\\n",
    "                                        'col_3':'col_3_fighter1', 'col_4':'col_4_fighter1', 'col_5':'col_5_fighter1',\\\n",
    "                                        'col_6':'col_6_fighter1', 'col_7':'col_7_fighter1',\\\n",
    "                                        'height':'height_fighter1', 'weight':'weight_fighter1', 'reach':'reach_fighter1',\\\n",
    "                                        'wins':'wins_fighter1', 'losses':'losses_fighter1', 'draws':'draws_fighter1',\\\n",
    "                                        'SLpM':'SLpM_fighter1','Str_Acc':'Str_Acc_fighter1', 'SApM':'SApM_fighter1',\\\n",
    "                                        'Str_Dep':'Str_Dep_fighter1', 'TD_Avg':'TD_Avg_fighter1', 'TD_Acc':'TD_Acc_fighter1',\\\n",
    "                                        'TD_Def':'TD_Def_fighter1', 'Sub_Avg':'Sub_Avg_fighter1'}, inplace=True)\n",
    "\n",
    "\n",
    "    # Get data for fighter 2\n",
    "\n",
    "    X_test = X_test.merge(fighter_data_relevant, left_on=['fighter2'], right_on=['full_name'],\\\n",
    "                                                    how='left').drop(columns=['full_name', 'fighter2'])\n",
    "    X_test.rename(columns={'col_0':'col_0_fighter2', 'col_1':'col_1_fighter2', 'col_2':'col_2_fighter2',\\\n",
    "                                        'col_3':'col_3_fighter2', 'col_4':'col_4_fighter2', 'col_5':'col_5_fighter2',\\\n",
    "                                        'col_6':'col_6_fighter2', 'col_7':'col_7_fighter2',\\\n",
    "                                        'height':'height_fighter2', 'weight':'weight_fighter2', 'reach':'reach_fighter2',\\\n",
    "                                        'wins':'wins_fighter2', 'losses':'losses_fighter2', 'draws':'draws_fighter2',\\\n",
    "                                        'SLpM':'SLpM_fighter2','Str_Acc':'Str_Acc_fighter2', 'SApM':'SApM_fighter2',\\\n",
    "                                        'Str_Dep':'Str_Dep_fighter2', 'TD_Avg':'TD_Avg_fighter2', 'TD_Acc':'TD_Acc_fighter2',\\\n",
    "                                        'TD_Def':'TD_Def_fighter2', 'Sub_Avg':'Sub_Avg_fighter2'}, inplace=True)\n",
    "\n",
    "    X_test = scale('standard', X_test)\n",
    "    \n",
    "    return(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & prepare training dataset\n",
    "X = scale('standard', fight_data_relevant.iloc[:,:-1])\n",
    "y = fight_data_relevant.iloc[:,-1]\n",
    "\n",
    "# Load & prepare dataset for prediction\n",
    "df_fight_card = pd.read_excel('../data/fight_card.xlsx', sheet_name='Sheet2')\n",
    "X_test = prepare_test_data(df_fight_card, fighter_data_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>fighter1</th>\n",
       "      <th>fighter2</th>\n",
       "      <th>Winner Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Women's Strawweight</td>\n",
       "      <td>Weili Zhang</td>\n",
       "      <td>Jessica Andrade</td>\n",
       "      <td>Weili Zhang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>Elizeu Zaleski dos Santos</td>\n",
       "      <td>Li Jingliang</td>\n",
       "      <td>Elizeu Zaleski dos Santos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Flyweight</td>\n",
       "      <td>Kai Kara-France</td>\n",
       "      <td>Mark De La Rosa</td>\n",
       "      <td>Kai Kara-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Women's Flyweight</td>\n",
       "      <td>Mizuki Inoue</td>\n",
       "      <td>Wu Yanan</td>\n",
       "      <td>Wu Yanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Middleweight</td>\n",
       "      <td>Israel Adesanya</td>\n",
       "      <td>Robert Whittaker</td>\n",
       "      <td>Israel Adesanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Lightweight</td>\n",
       "      <td>Dustin Poirier</td>\n",
       "      <td>Khabib Nurmagomedov</td>\n",
       "      <td>Khabib Nurmagomedov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>Song Kenan</td>\n",
       "      <td>Derrick Krantz</td>\n",
       "      <td>Song Kenan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weight_class                   fighter1             fighter2  \\\n",
       "0  Women's Strawweight                Weili Zhang      Jessica Andrade   \n",
       "1         Welterweight  Elizeu Zaleski dos Santos         Li Jingliang   \n",
       "2            Flyweight            Kai Kara-France      Mark De La Rosa   \n",
       "3    Women's Flyweight               Mizuki Inoue             Wu Yanan   \n",
       "4         Middleweight            Israel Adesanya     Robert Whittaker   \n",
       "5          Lightweight             Dustin Poirier  Khabib Nurmagomedov   \n",
       "6         Welterweight                 Song Kenan       Derrick Krantz   \n",
       "\n",
       "           Winner Prediction  \n",
       "0                Weili Zhang  \n",
       "1  Elizeu Zaleski dos Santos  \n",
       "2            Kai Kara-France  \n",
       "3                   Wu Yanan  \n",
       "4            Israel Adesanya  \n",
       "5        Khabib Nurmagomedov  \n",
       "6                 Song Kenan  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "                 'n_estimators' : 500, 'boosting_type' : 'dart'\n",
    "                 }\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(**lgb_params)\n",
    "lgbm.fit(X, y)\n",
    "# lgbm_score = lgbm.score(X, y)\n",
    "# print (f'LightGBM score on test data = {lgbm_score*100:.2f}%')\n",
    "\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "preds = []\n",
    "\n",
    "for idx, val in enumerate(y_pred_lgbm):\n",
    "    if (val == 0):\n",
    "        preds.append(df_fight_card.fighter1[idx])\n",
    "    else:\n",
    "        preds.append(df_fight_card.fighter2[idx])\n",
    "\n",
    "df_fight_card['Winner Prediction'] = preds\n",
    "\n",
    "df_fight_card\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_class</th>\n",
       "      <th>fighter1</th>\n",
       "      <th>fighter2</th>\n",
       "      <th>Winner Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Women's Strawweight</td>\n",
       "      <td>Jessica Andrade</td>\n",
       "      <td>Weili Zhang</td>\n",
       "      <td>Weili Zhang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>Li Jingliang</td>\n",
       "      <td>Elizeu Zaleski dos Santos</td>\n",
       "      <td>Elizeu Zaleski dos Santos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Flyweight</td>\n",
       "      <td>Mark De La Rosa</td>\n",
       "      <td>Kai Kara-France</td>\n",
       "      <td>Kai Kara-France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Women's Flyweight</td>\n",
       "      <td>Wu Yanan</td>\n",
       "      <td>Mizuki Inoue</td>\n",
       "      <td>Wu Yanan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Middleweight</td>\n",
       "      <td>Robert Whittaker</td>\n",
       "      <td>Israel Adesanya</td>\n",
       "      <td>Israel Adesanya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Lightweight</td>\n",
       "      <td>Khabib Nurmagomedov</td>\n",
       "      <td>Dustin Poirier</td>\n",
       "      <td>Khabib Nurmagomedov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Welterweight</td>\n",
       "      <td>Derrick Krantz</td>\n",
       "      <td>Song Kenan</td>\n",
       "      <td>Song Kenan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          weight_class             fighter1                   fighter2  \\\n",
       "0  Women's Strawweight      Jessica Andrade                Weili Zhang   \n",
       "1         Welterweight         Li Jingliang  Elizeu Zaleski dos Santos   \n",
       "2            Flyweight      Mark De La Rosa            Kai Kara-France   \n",
       "3    Women's Flyweight             Wu Yanan               Mizuki Inoue   \n",
       "4         Middleweight     Robert Whittaker            Israel Adesanya   \n",
       "5          Lightweight  Khabib Nurmagomedov             Dustin Poirier   \n",
       "6         Welterweight       Derrick Krantz                 Song Kenan   \n",
       "\n",
       "           Winner Prediction  \n",
       "0                Weili Zhang  \n",
       "1  Elizeu Zaleski dos Santos  \n",
       "2            Kai Kara-France  \n",
       "3                   Wu Yanan  \n",
       "4            Israel Adesanya  \n",
       "5        Khabib Nurmagomedov  \n",
       "6                 Song Kenan  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fight_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('outputs/lgbm1.pkl', 'wb') as pklfile:\n",
    "#     pickle.dump(lgbm, pklfile)\n",
    "lgb_params = {\n",
    "                 'n_estimators' : 500, 'boosting_type' : 'dart'\n",
    "                 }\n",
    "\n",
    "with open('outputs/lgbm1.pkl', 'rb') as pklfile:\n",
    "    lgbm = pickle.load(pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load & prepare training dataset\n",
    "X = scale('standard', fight_data_relevant.iloc[:,:-1])\n",
    "y = fight_data_relevant.iloc[:,-1]\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "# estimator = KerasClassifier(build_fn=model1(X, y), epochs=100, batch_size=32, verbose=0)\n",
    "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "# results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# print(f'Results: {results.mean()*100}, {results.std()*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_hist(history):\n",
    "  history_dict=history.history\n",
    "  loss_values = history_dict['loss']\n",
    "  val_loss_values=history_dict['val_loss']\n",
    "  plt.figure(figsize=(10,6))\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.plot(loss_values, color='Blue', linestyle='dashed', marker='o', label='Training Loss')\n",
    "  plt.plot(val_loss_values,color='Red', label='Validation Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def model1(X, y):\n",
    "  name = 'Model 1'\n",
    "\n",
    "  input_shape = X[0].shape\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, input_shape=input_shape, kernel_initializer='normal', activation='relu'))\n",
    "  model.add(Dense(64, activation='relu'))\n",
    "#   model.add(Dropout(0.2))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  model.compile(optimizer='adam', \n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  # Runs model and assigns it to 'history'\n",
    "  history = model.fit(X, y, epochs = 10, batch_size=32, validation_split = 0.3, verbose=1)\n",
    "\n",
    "#   y_pred = model.predict(X)\n",
    "#   print(f'{name}: Accuracy the Train set is:\\t{accuracy_score(y, y_pred):.3f}')\n",
    "  \n",
    "  # Plot Training & Validation Loss\n",
    "  plot_hist(history)\n",
    "  \n",
    "  return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model_1.predict(X)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "iters = 1\n",
    "\n",
    "for iter in range(iters):\n",
    "  model_1 = model1(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Experiment, Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version 1.0.57 of the Azure ML SDK\n",
      "\n",
      "Workspace name: one618\n",
      "Azure region: eastus2\n",
      "Subscription id: e5b717fe-4eb6-4f16-a1d1-4aa76afd41fd\n",
      "Resource group: axemlrg1\n"
     ]
    }
   ],
   "source": [
    "print(\"Using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(f'Workspace name: {ws.name}\\n\\\n",
    "Azure region: {ws.location}\\n\\\n",
    "Subscription id: {ws.subscription_id}\\n\\\n",
    "Resource group: {ws.resource_group}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'myexp': Experiment(Name: myexp,\n",
       " Workspace: one618), 'mma-predictions': Experiment(Name: mma-predictions,\n",
       " Workspace: one618)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-2f7a2d7f8027>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mct\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "for ct in ws.compute_targets():\n",
    "    print (ct.name, ct.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Converted key lgb_params of value {'n_estimators': 500, 'boosting_type': 'dart'} to {'n_estimators': 500, 'boosting_type': 'dart'}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an experiment object from Azure Machine Learning\n",
    "experiment = Experiment(workspace=ws, name=\"mma-predictions\")\n",
    "\n",
    "# Create a run object in the experiment\n",
    "run =  experiment.start_logging()\n",
    "# Log the algorithm parameters to the run\n",
    "run.log('lgb_params', lgb_params)\n",
    "\n",
    "# Model file\n",
    "model_file_name = 'outputs/lgbm1.pkl'\n",
    "\n",
    "# upload the model file explicitly into artifacts \n",
    "run.upload_file(name = model_file_name, path_or_stream = model_file_name)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>mma-predictions</td><td>62a046da-0a82-445b-bbda-3c265c20bff1</td><td></td><td>Running</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/e5b717fe-4eb6-4f16-a1d1-4aa76afd41fd/resourceGroups/axemlrg1/providers/Microsoft.MachineLearningServices/workspaces/one618/experiments/mma-predictions/runs/62a046da-0a82-445b-bbda-3c265c20bff1\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: mma-predictions,\n",
       "Id: 62a046da-0a82-445b-bbda-3c265c20bff1,\n",
       "Type: None,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/lgbm1.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Register the model with the workspace\n",
    "model = run.register_model(model_name='lgbm1', model_path='outputs/lgbm1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbm1 2\n",
      "lgbm1 1\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "models = Model.list(ws, name='lgbm1')\n",
    "for m in models:\n",
    "    print(m.name, m.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "- lightgbm\n",
      "- pandas\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# Create an empty conda environment and add the scikit-learn package\n",
    "env = CondaDependencies()\n",
    "env.add_conda_package(\"scikit-learn\")\n",
    "env.add_conda_package(\"lightgbm\")\n",
    "env.add_conda_package(\"pandas\")\n",
    "\n",
    "# Display the environment\n",
    "print(env.serialize_to_string())\n",
    "\n",
    "# Write the environment to disk\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(env.serialize_to_string())\n",
    "\n",
    "# Create a configuration object indicating how our deployment container needs to be created\n",
    "image_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n",
    "                                    runtime=\"python\", \n",
    "                                    conda_file=\"myenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={'sample name': 'MMA Predict'}, \n",
    "                                               description='MMA fight predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Error, there is already a service with name mma-fightpredict-svc found in workspace one618\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error, there is already a service with name mma-fightpredict-svc found in workspace one618\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error, there is already a service with name mma-fightpredict-svc found in workspace one618\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\u001b[0m in \u001b[0;36m_check_for_existing_webservice\u001b[1;34m(workspace, name)\u001b[0m\n\u001b[0;32m    361\u001b[0m             raise WebserviceException('Error, there is already a service with name {} found in '\n\u001b[1;32m--> 362\u001b[1;33m                                       'workspace {}'.format(name, workspace._workspace_name))\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mWebserviceException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error, there is already a service with name mma-fightpredict-svc found in workspace one618\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error, there is already a service with name mma-fightpredict-svc found in workspace one618\"\n    }\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\u001b[0m in \u001b[0;36mdeploy_from_model\u001b[1;34m(workspace, name, models, image_config, deployment_config, deployment_target)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mwebservice_name_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mWebservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_for_local_deployment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mWebservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_for_existing_webservice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\azureml\\core\\webservice\\webservice.py\u001b[0m in \u001b[0;36m_check_for_existing_webservice\u001b[1;34m(workspace, name)\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mWebserviceException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'WebserviceNotFound'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error, there is already a service with name mma-fightpredict-svc found in workspace one618\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error, there is already a service with name mma-fightpredict-svc found in workspace one618\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "# Create the webservice using all of the precreated configurations and our best model\n",
    "service = Webservice.deploy_from_model(name='mma-fightpredict-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       models=[model],\n",
    "                                       image_config=image_config,\n",
    "                                       workspace=ws)\n",
    "\n",
    "# Wait for the service deployment to complete while displaying log output\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-02T12:24:38,699679792+00:00 - rsyslog/run \n",
      "2019-09-02T12:24:38,704938840+00:00 - iot-server/run \n",
      "2019-09-02T12:24:38,712771610+00:00 - gunicorn/run \n",
      "2019-09-02T12:24:38,714739328+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-09-02T12:24:39,114386733+00:00 - iot-server/finish 1 0\n",
      "2019-09-02T12:24:39,116496752+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 46\n",
      "Exception in worker process\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/arbiter.py\", line 583, in spawn_worker\n",
      "    worker.init_process()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 129, in init_process\n",
      "    self.load_wsgi()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/workers/base.py\", line 138, in load_wsgi\n",
      "    self.wsgi = self.app.wsgi()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/app/base.py\", line 67, in wsgi\n",
      "    self.callable = self.load()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 52, in load\n",
      "    return self.load_wsgiapp()\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py\", line 41, in load_wsgiapp\n",
      "    return util.import_app(self.app_uri)\n",
      "  File \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/util.py\", line 350, in import_app\n",
      "    __import__(module)\n",
      "  File \"/var/azureml-server/wsgi.py\", line 1, in <module>\n",
      "    import create_app\n",
      "  File \"/var/azureml-server/create_app.py\", line 3, in <module>\n",
      "    from app import main\n",
      "  File \"/var/azureml-server/app.py\", line 13, in <module>\n",
      "    import main as user_main\n",
      "  File \"/var/azureml-app/main.py\", line 18, in <module>\n",
      "    driver_module_spec.loader.exec_module(driver_module)\n",
      "  File \"score.py\", line 5, in <module>\n",
      "    import category_encoders as ce\n",
      "ModuleNotFoundError: No module named 'category_encoders'\n",
      "Worker exiting (pid: 46)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2019-09-02T12:24:44,459721246+00:00 - gunicorn/finish 3 0\n",
      "2019-09-02T12:24:44,461529762+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Error attempting to call webservice, scoring_uri unavailable. This could be due to a failed deployment, or the service is not ready yet.\n",
      "Current State: None\n",
      "Errors: None\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error attempting to call webservice, scoring_uri unavailable. This could be due to a failed deployment, or the service is not ready yet.\nCurrent State: None\nErrors: None\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error attempting to call webservice, scoring_uri unavailable. This could be due to a failed deployment, or the service is not ready yet.\\nCurrent State: None\\nErrors: None\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-2aa1605cc42d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#score on our service\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\data\\code\\python\\mma_predictions\\lib\\site-packages\\azureml\\core\\webservice\\aci.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                       \u001b[1;34m'This could be due to a failed deployment, or the service is not ready yet.\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                                       \u001b[1;34m'Current State: {}\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m                                       'Errors: {}'.format(self.state, self.error), logger=module_logger)\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClientBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_webservice_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error attempting to call webservice, scoring_uri unavailable. This could be due to a failed deployment, or the service is not ready yet.\nCurrent State: None\nErrors: None\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error attempting to call webservice, scoring_uri unavailable. This could be due to a failed deployment, or the service is not ready yet.\\nCurrent State: None\\nErrors: None\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "service = ws.webservices['mma-fight-predict-svc']\n",
    "\n",
    "# scrape the first row from the test set.\n",
    "test_samples = X_test\n",
    "\n",
    "#score on our service\n",
    "service.run(input_data = test_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
